{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dialogflow_v2 as dialogflow\n",
    "import os\n",
    "\n",
    "credentials_file = 'devbot-qludto-c49ed3f01f08.json'  \n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_file\n",
    "\n",
    "from google.oauth2 import service_account\n",
    "credentials = service_account.Credentials.from_service_account_file(credentials_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_intent(project_id, display_name, training_phrases_parts, message_texts):\n",
    "    \"\"\"Create an intent of the given intent type.\"\"\"\n",
    "    #import dialogflow_v2 as dialogflow\n",
    "    intents_client = dialogflow.IntentsClient(credentials=credentials)\n",
    "\n",
    "    parent = intents_client.project_agent_path(project_id)\n",
    "    training_phrases = []\n",
    "    for training_phrases_part in training_phrases_parts:\n",
    "        part = dialogflow.types.Intent.TrainingPhrase.Part(\n",
    "            text=training_phrases_part)\n",
    "        # Here we create a new training phrase for each provided part.\n",
    "        training_phrase = dialogflow.types.Intent.TrainingPhrase(parts=[part])\n",
    "        training_phrases.append(training_phrase)\n",
    "\n",
    "    text = dialogflow.types.Intent.Message.Text(text=message_texts)\n",
    "    message = dialogflow.types.Intent.Message(text=text)\n",
    "\n",
    "    intent = dialogflow.types.Intent(\n",
    "        display_name=display_name,\n",
    "        training_phrases=training_phrases,\n",
    "        messages=[message])\n",
    "\n",
    "    response = intents_client.create_intent(parent, intent)\n",
    "\n",
    "    print('Intent created: {}'.format(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'newagent-fpxjnq'\n",
    "language_code = ''\n",
    "display_name = list(['delete', 'transfer', 'alarm'])\n",
    "training_phrases_parts = list([['delete the row please.', 'delete the column please.'],\n",
    "                            ['transfer 50 euro please', 'i want to make transfer', 'transfer money'],\n",
    "                            ['set alarm', 'set clock at 6', 'remind me at 9pm']])\n",
    "message_texts = None #'delete the value'\n",
    "\n",
    "#credentials_file = 'NewAgent-676cf2e40a3f.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_intent(project_id, display_name, training_phrases_parts, message_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create intents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent created: name: \"projects/newagent-fpxjnq/agent/intents/c2a01474-1e27-41a8-8709-861ad05dec7c\"\n",
      "display_name: \"delete\"\n",
      "priority: 500000\n",
      "messages {\n",
      "  text {\n",
      "  }\n",
      "}\n",
      "\n",
      "Intent created: name: \"projects/newagent-fpxjnq/agent/intents/c2687222-2a85-44ae-a192-0b5297863033\"\n",
      "display_name: \"transfer\"\n",
      "priority: 500000\n",
      "messages {\n",
      "  text {\n",
      "  }\n",
      "}\n",
      "\n",
      "Intent created: name: \"projects/newagent-fpxjnq/agent/intents/e4de3247-0e1e-42ea-8d3e-6a97e5da205f\"\n",
      "display_name: \"alarm\"\n",
      "priority: 500000\n",
      "messages {\n",
      "  text {\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "intents_client = dialogflow.IntentsClient()\n",
    "parent = intents_client.project_agent_path(project_id)\n",
    "\n",
    "for i in range(len(display_name)):\n",
    "    training_phrases = []\n",
    "    for training_phrases_part in training_phrases_parts[i]:\n",
    "        part = dialogflow.types.Intent.TrainingPhrase.Part(\n",
    "            text=training_phrases_part)\n",
    "        # Here we create a new training phrase for each provided part.\n",
    "        training_phrase = dialogflow.types.Intent.TrainingPhrase(parts=[part])\n",
    "        training_phrases.append(training_phrase)\n",
    "\n",
    "    text = dialogflow.types.Intent.Message.Text(text=message_texts)\n",
    "    message = dialogflow.types.Intent.Message(text=text)\n",
    "\n",
    "    intent = dialogflow.types.Intent(\n",
    "        display_name=display_name[i],\n",
    "        training_phrases=training_phrases,\n",
    "        messages=[message])\n",
    "\n",
    "    response = intents_client.create_intent(parent, intent)\n",
    "\n",
    "    print('Intent created: {}'.format(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training the agent model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dialogflow.AgentsClient()\n",
    "\n",
    "parent = client.project_path(project_id)\n",
    "\n",
    "response = client.train_agent(parent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the intent ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['e4de3247-0e1e-42ea-8d3e-6a97e5da205f']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = display_name[2]\n",
    "\n",
    "intents_client = dialogflow.IntentsClient()\n",
    "parent = intents_client.project_agent_path(project_id)\n",
    "\n",
    "intents = intents_client.list_intents(parent)\n",
    "\n",
    "intent_names = [\n",
    "    intent.name for intent in intents\n",
    "    if intent.display_name == name]\n",
    "\n",
    "intent_ids = [\n",
    "    intent_name.split('/')[-1] for intent_name\n",
    "    in intent_names]\n",
    "\n",
    "intent_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detect the intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query text: set alarm\n",
      "Detected intent: alarm\n",
      "Detected intent confidence: 1.0\n"
     ]
    }
   ],
   "source": [
    "project_id = 'devbot-qludto'\n",
    "\n",
    "DIALOGFLOW_PROJECT_ID = project_id\n",
    "DIALOGFLOW_LANGUAGE_CODE = 'en'\n",
    "SESSION_ID = '1'\n",
    "\n",
    "\n",
    "#text_to_be_analyzed = \"transfer money\"\n",
    "text_to_be_analyzed = \"set alarm\"\n",
    "\n",
    "\n",
    "session_client = dialogflow.SessionsClient()\n",
    "session = session_client.session_path(DIALOGFLOW_PROJECT_ID, SESSION_ID)\n",
    "\n",
    "text_input = dialogflow.types.TextInput(text=text_to_be_analyzed, language_code=DIALOGFLOW_LANGUAGE_CODE)\n",
    "query_input = dialogflow.types.QueryInput(text=text_input)\n",
    "\n",
    "try:\n",
    "    response = session_client.detect_intent(session=session, query_input=query_input)\n",
    "except InvalidArgument:\n",
    "    raise\n",
    "\n",
    "print(\"Query text:\", response.query_result.query_text)\n",
    "print(\"Detected intent:\", response.query_result.intent.display_name)\n",
    "print(\"Detected intent confidence:\", response.query_result.intent_detection_confidence)\n",
    "#print(\"Fulfillment text:\", response.query_result.fulfillment_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# delete all intents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "finished!\n"
    }
   ],
   "source": [
    "project_id = 'devbot-qludto'\n",
    "\n",
    "client = dialogflow.IntentsClient()\n",
    "\n",
    "parent = client.project_agent_path(project_id)\n",
    "\n",
    "intents = client.list_intents(parent)\n",
    "for i in intents:\n",
    "    print(i.display_name)\n",
    "\n",
    "print('finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data.dropna(axis=0, how='any', inplace=True) \n",
    "\n",
    "client = dialogflow.IntentsClient()\n",
    "\n",
    "parent = client.project_agent_path(project_id)\n",
    "\n",
    "intents = client.list_intents(parent)\n",
    "\n",
    "response = client.batch_delete_intents(parent, intents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents = client.list_intents(parent)\n",
    "for i in intents:\n",
    "    print(i.display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def detect_intent(project_id, text_to_be_analyzed):\n",
    "    DIALOGFLOW_PROJECT_ID = project_id\n",
    "    DIALOGFLOW_LANGUAGE_CODE = 'en'\n",
    "    SESSION_ID = '1'\n",
    "\n",
    "    #text_to_be_analyzed = \"transfer money\"\n",
    "    text_to_be_analyzed = text_to_be_analyzed #\"set alarm\"\n",
    "\n",
    "\n",
    "    session_client = dialogflow.SessionsClient()\n",
    "    session = session_client.session_path(DIALOGFLOW_PROJECT_ID, SESSION_ID)\n",
    "\n",
    "    text_input = dialogflow.types.TextInput(text=text_to_be_analyzed, language_code=DIALOGFLOW_LANGUAGE_CODE)\n",
    "    query_input = dialogflow.types.QueryInput(text=text_input)\n",
    "\n",
    "    try:\n",
    "        response = session_client.detect_intent(session=session, query_input=query_input)\n",
    "        return response.query_result.intent.display_name\n",
    "    \n",
    "    except: #InvalidArgument:\n",
    "        pass #raise\n",
    "        \n",
    "    '''\n",
    "    print(\"Query text:\", response.query_result.query_text)\n",
    "    print(\"Detected intent:\", response.query_result.intent.display_name)\n",
    "    print(\"Detected intent confidence:\", response.query_result.intent_detection_confidence)\n",
    "    #print(\"Fulfillment text:\", response.query_result.fulfillment_text)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def eval_intent(project_id, test_data, write_file):  # input test data shoulb be in format .csv\n",
    "    \n",
    "    for i in range(len(test_data)):\n",
    "        if i % 150 == 1:\n",
    "            time.sleep(65)\n",
    "            print('Evaluating intent need to sleep for 65s!')\n",
    "\n",
    "        pred_intent = detect_intent(project_id, test_data.loc[i, 'Phrase'])\n",
    "        test_data.loc[i, 'Pred_intent'] = pred_intent\n",
    "        \n",
    "    test_data.dropna(axis=0, how='any', inplace=True)  \n",
    "    test_data.to_csv('./dialogflow_result/test_data_result.csv')\n",
    "    print('Evaluation is done!')\n",
    "    \n",
    "    \n",
    "    intent_set = list(set(list(test_data.Intent.unique()) + list(test_data.Pred_intent.unique())))\n",
    "    con_mat =  np.zeros([len(intent_set), len(intent_set)])  # True * Prediction\n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        con_mat[intent_set.index(test_data.loc[i, 'Intent']), intent_set.index(test_data.loc[i, 'Pred_intent'])] += 1\n",
    "        np.save(write_file+'/con_mat.npy', con_mat)\n",
    "    print('confusion matrix is done!')\n",
    "\n",
    "    \n",
    "    TP,TN,FP,FN,accuracy,precision,recall,f1 = 0,0,0,0,0,0,0,0\n",
    "    precision_sum, recall_sum, f1_sum = 0,0,0\n",
    "    d = 0\n",
    "    for i in range(len(con_mat)-1):\n",
    "        TP = con_mat[i][i]\n",
    "        FN = (np.sum(con_mat[i, :i]) + np.sum(con_mat[i, i+1:]))\n",
    "        FP = (np.sum(con_mat[:i, i]) + np.sum(con_mat[i+1:, i]))\n",
    "        TN = (np.sum(con_mat) - TP - FN - FP)\n",
    "\n",
    "        if  (TP + FP) != 0 and  (TP + FN) != 0:\n",
    "            d += 1\n",
    "            accuracy += TP / (TP + TN + FP + FN)\n",
    "\n",
    "            precision = TP / (TP + FP)\n",
    "            precision_sum += precision\n",
    "\n",
    "            recall = TP / (TP + FN)\n",
    "            recall_sum += recall\n",
    "\n",
    "            f1 = (2 * precision * recall / (precision + recall))\n",
    "            f1_sum += f1\n",
    "    print(accuracy,precision,recall,f1)\n",
    "\n",
    "    TP = con_mat[-1][-1]\n",
    "    FN = np.sum(con_mat[len(con_mat)-1, :len(con_mat)-1])\n",
    "    FP = np.sum(con_mat[:len(con_mat)-1, len(con_mat)-1])\n",
    "    TN = (np.sum(con_mat) - TP - FN - FP)\n",
    "\n",
    "    if  (TP + FP) != 0 and  (TP + FN) != 0:\n",
    "        d += 1\n",
    "        accuracy += TP / (TP + TN + FP + FN)\n",
    "\n",
    "        precision = TP / (TP + FP)\n",
    "        precision_sum += precision\n",
    "\n",
    "        recall = TP / (TP + FN)\n",
    "        recall_sum += recall\n",
    "\n",
    "        f1 = (2 * precision * recall / (precision + recall))\n",
    "        f1_sum += f1\n",
    "\n",
    "    print(accuracy, precision_sum/d, recall_sum/d, f1_sum/d)\n",
    "\n",
    "    overall_accuracy, overall_precision, overall_f1 = accuracy, precision_sum/d, f1_sum/d\n",
    "    \n",
    "    return overall_accuracy, overall_precision, overall_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'newagent-fpxjnq'\n",
    "df_test = pd.read_csv('./data/df_test.csv', index_col=0)\n",
    "eval_metrics = []\n",
    "sub_file_name = 'name'\n",
    "write_file = './dialogflow_result/sub_datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n",
      "Evaluating intent need to sleep for 65s!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "  File \"<ipython-input-4-8d342b6dd97a>\", line 2, in <module>\n",
      "    overall_accuracy, overall_precision, overall_f1_score = eval_intent(project_id, df_test, write_file)\n",
      "  File \"<ipython-input-2-ac239fe20823>\", line 44, in eval_intent\n",
      "    pred_intent = detect_intent(project_id, test_data.loc[i, 'Phrase'])\n",
      "  File \"<ipython-input-2-ac239fe20823>\", line 14, in detect_intent\n",
      "    session_client = dialogflow.SessionsClient()\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/site-packages/dialogflow_v2/gapic/sessions_client.py\", line 187, in __init__\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/site-packages/dialogflow_v2/gapic/transports/sessions_grpc_transport.py\", line 69, in __init__\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/site-packages/dialogflow_v2/gapic/transports/sessions_grpc_transport.py\", line 99, in create_channel\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\", line 177, in create_channel\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/site-packages/google/auth/_default.py\", line 308, in default\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/site-packages/google/auth/_default.py\", line 166, in _get_explicit_environ_credentials\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/site-packages/google/auth/_default.py\", line 95, in _load_credentials_from_file\n",
      "OSError: [Errno 24] Too many open files: 'newagent-fpxjnq-08c3138e5a20.json'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "AttributeError: 'OSError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/inspect.py\", line 725, in getmodule\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/inspect.py\", line 709, in getabsfile\n",
      "  File \"/Users/xinsun/anaconda3/envs/dev/lib/python3.7/posixpath.py\", line 383, in abspath\n",
      "OSError: [Errno 24] Too many open files\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 24] Too many open files: 'newagent-fpxjnq-08c3138e5a20.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# rasa NLU models evaluation part.\n",
    "overall_accuracy, overall_precision, overall_f1_score = eval_intent(project_id, df_test, write_file)\n",
    "eval_metrics.append([sub_file_name, overall_accuracy, overall_precision, overall_f1_score])\n",
    "\n",
    "result = pd.DataFrame(eval_metrics, columns=['model_name', 'overall_accuracy', 'overall_precision', 'overall_f1_score'])\n",
    "result.to_csv('./dialogflow_result/dialogflow_eval_result.csv')   # have to remove all previous result.csv at first\n",
    "print('The agent is evaluated successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('finish!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "151\n['roll_dice', 'make_call', 'tire_change', 'damaged_card', 'food_last', 'current_location', 'routing', 'play_music', 'timezone', 'date', 'plug_type', 'what_can_i_ask_you', 'cancel', 'shopping_list_update', 'income', 'pto_used', 'distance', 'how_old_are_you', 'confirm_reservation', 'traffic', 'recipe', 'lost_luggage', 'restaurant_reservation', 'uber', 'pay_bill', 'goodbye', 'book_flight', 'calculator', 'yes', 'text', 'redeem_rewards', 'international_visa', 'vaccines', 'credit_limit_change', 'insurance_change', 'mpg', 'change_accent', 'calendar_update', 'calendar', 'timer', 'carry_on', 'ingredients_list', 'payday', 'alarm', 'schedule_meeting', 'account_blocked', 'meeting_schedule', 'spending_history', 'transfer', 'restaurant_reviews', 'report_fraud', 'car_rental', 'flip_coin', 'pin_change', 'insurance', 'find_phone', 'next_holiday', 'gas', 'who_do_you_work_for', 'how_busy', 'restaurant_suggestion', 'cancel_reservation', 'oos', 'pto_request', 'repeat', 'change_volume', 'nutrition_info', 'credit_score', 'time', 'smart_home', 'interest_rate', 'flight_status', 'bill_balance', 'expiration_date', 'user_name', 'travel_alert', 'travel_notification', 'shopping_list', 'rewards_balance', 'balance', 'no', 'measurement_conversion', 'change_ai_name', 'share_location', 'sync_device', 'definition', 'maybe', 'bill_due', 'cook_time', 'reset_settings', 'next_song', 'freeze_account', 'oil_change_when', 'w2', 'credit_limit', 'international_fees', 'order_checks', 'accept_reservations', 'who_made_you', 'where_are_you_from', 'change_user_name', 'calories', 'spelling', 'meal_suggestion', 'meaning_of_life', 'order', 'tell_joke', 'gas_type', 'weather', 'ingredient_substitution', 'order_status', 'exchange_rate', 'travel_suggestion', 'are_you_a_bot', 'direct_deposit', 'schedule_maintenance', 'change_speed', 'thank_you', 'last_maintenance', 'transactions', 'pto_request_status', 'apr', 'do_you_have_pets', 'pto_balance', 'report_lost_card', 'rollover_401k', 'fun_fact', 'greeting', 'reminder_update', 'translate', 'tire_pressure', 'what_song', 'whisper_mode', 'application_status', 'book_hotel', 'change_language', 'todo_list_update', 'what_are_your_hobbies', 'update_playlist', 'jump_start', 'what_is_your_name', 'taxes', 'improve_credit_score', 'reminder', 'card_declined', 'replacement_card_duration', 'oil_change_how', 'min_payment', 'directions', 'new_card', 'todo_list']\n"
    }
   ],
   "source": [
    "test_data = pd.read_csv('./dialogflow_result/test_data_result.csv', index_col=0)\n",
    "\n",
    "test_data.dropna(axis=0, how='any', inplace=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "intent_set = list(set(list(test_data.Intent.unique()) + list(test_data.Pred_intent.unique())))\n",
    "\n",
    "con_mat =  np.zeros([len(intent_set), len(intent_set)])  # True * Prediction\n",
    "print(len(intent_set))\n",
    "print(intent_set) \n",
    "\n",
    "for i in range(len(test_data)):\n",
    "    #print(test_data.loc[i, 'Intent'])\n",
    "    #print(test_data.loc[i, 'Pred_intent'])\n",
    "    try:\n",
    "        test_data.loc[i, 'Intent']\n",
    "        test_data.loc[i, 'Pred_intent']\n",
    "    except:print(i)\n",
    "    #con_mat[intent_set.index(test_data.loc[i, 'Intent'])][intent_set.index(test_data.loc[i, 'Pred_intent'])] += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "Phrase         speak in french please\nIntent                change_language\nPred_intent           change_language\nName: 332, dtype: object"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.loc[332]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8060000000000005 0.8571428571428571 0.8 0.8275862068965518\n",
      "0.8360000000000005 0.9550415457856802 0.8392156862745095 0.8862033722288207\n",
      "34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(con_mat)-1):\\n    TP += con_mat[i][i]\\n    FN += (np.sum(con_mat[i, :i]) + np.sum(con_mat[i, i+1:]))\\n    FP += (np.sum(con_mat[:i, i]) + np.sum(con_mat[i+1:, i]))\\nprint(TP,FN,FP)\\n\\n\\nTP += con_mat[-1][-1]\\nFN += np.sum(con_mat[len(con_mat)-1, :len(con_mat)-1])\\nFP += np.sum(con_mat[:len(con_mat)-1, len(con_mat)-1])\\nprint(TP,FN,FP)\\n\\naccuracy = TP / np.sum(con_mat)\\nprecision = TP / (TP + FP)\\nrecall = TP / (TP + FN)\\nf1 = 2 * precision * recall / (precision + recall)\\nprint(accuracy,precision,recall,f1,np.sum(con_mat))\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP,TN,FP,FN,accuracy,precision,recall,f1 = 0,0,0,0,0,0,0,0\n",
    "precision_sum, recall_sum, f1_sum = 0,0,0\n",
    "\n",
    "d = 0\n",
    "for i in range(len(con_mat)-1):\n",
    "    TP = con_mat[i][i]\n",
    "    FN = (np.sum(con_mat[i, :i]) + np.sum(con_mat[i, i+1:]))\n",
    "    FP = (np.sum(con_mat[:i, i]) + np.sum(con_mat[i+1:, i]))\n",
    "    TN = (np.sum(con_mat) - TP - FN - FP)\n",
    "    #(np.sum(con_mat[:i, :i]) + np.sum(con_mat[i+1:, i+1:]) + np.sum(con_mat[:i, i+1:]) + np.sum(con_mat[i+1:, :i]) - TP - TN - FP)\n",
    "    if  (TP + FP) != 0 and  (TP + FN) != 0:\n",
    "        d += 1\n",
    "        accuracy += TP / (TP + TN + FP + FN)\n",
    "        \n",
    "        precision = TP / (TP + FP)\n",
    "        precision_sum += precision\n",
    "        \n",
    "        recall = TP / (TP + FN)\n",
    "        recall_sum += recall\n",
    "        \n",
    "        f1 = (2 * precision * recall / (precision + recall))\n",
    "        f1_sum += f1\n",
    "        \n",
    "print(accuracy,precision,recall,f1)\n",
    "\n",
    "\n",
    "TP = con_mat[-1][-1]\n",
    "FN = np.sum(con_mat[len(con_mat)-1, :len(con_mat)-1])\n",
    "FP = np.sum(con_mat[:len(con_mat)-1, len(con_mat)-1])\n",
    "TN = (np.sum(con_mat) - TP - FN - FP)\n",
    "#print(TP,FN,FP,TN)\n",
    "\n",
    "if  (TP + FP) != 0 and  (TP + FN) != 0:\n",
    "    d += 1\n",
    "    accuracy += TP / (TP + TN + FP + FN)\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    precision_sum += precision\n",
    "\n",
    "    recall = TP / (TP + FN)\n",
    "    recall_sum += recall\n",
    "\n",
    "    f1 = (2 * precision * recall / (precision + recall))\n",
    "    f1_sum += f1\n",
    "    \n",
    "print(accuracy, precision_sum/d, recall_sum/d, f1_sum/d)\n",
    "\n",
    "print(d)\n",
    "\n",
    "'''\n",
    "for i in range(len(con_mat)-1):\n",
    "    TP += con_mat[i][i]\n",
    "    FN += (np.sum(con_mat[i, :i]) + np.sum(con_mat[i, i+1:]))\n",
    "    FP += (np.sum(con_mat[:i, i]) + np.sum(con_mat[i+1:, i]))\n",
    "print(TP,FN,FP)\n",
    "\n",
    "\n",
    "TP += con_mat[-1][-1]\n",
    "FN += np.sum(con_mat[len(con_mat)-1, :len(con_mat)-1])\n",
    "FP += np.sum(con_mat[:len(con_mat)-1, len(con_mat)-1])\n",
    "print(TP,FN,FP)\n",
    "\n",
    "accuracy = TP / np.sum(con_mat)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(accuracy,precision,recall,f1,np.sum(con_mat))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.836\n",
      "precision:  0.836\n",
      "f1:  0.836\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ', accuracy)\n",
    "print('precision: ', precision)\n",
    "print('f1: ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = './data/df_test.csv'\n",
    "ids = np.random.randint(0,5400,3000)\n",
    "df_test = pd.read_csv(test_data, index_col=0).loc[ids].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)\n",
    "max(ids)\n",
    "min(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Phrase</th>\n      <th>Intent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>tell me what the gas mileage is on my car</td>\n      <td>mpg</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>i'd like to know the last time my car got look...</td>\n      <td>last_maintenance</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>can i put in a pto request for september 1st t...</td>\n      <td>pto_request</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>did carrots get on my shopping list</td>\n      <td>shopping_list</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>will i get charged for using my credit card in...</td>\n      <td>international_fees</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>2995</td>\n      <td>date please</td>\n      <td>date</td>\n    </tr>\n    <tr>\n      <td>2996</td>\n      <td>when will i received a replacement card</td>\n      <td>replacement_card_duration</td>\n    </tr>\n    <tr>\n      <td>2997</td>\n      <td>tell ann and scott where i am</td>\n      <td>share_location</td>\n    </tr>\n    <tr>\n      <td>2998</td>\n      <td>can you please disconnect from my phone</td>\n      <td>sync_device</td>\n    </tr>\n    <tr>\n      <td>2999</td>\n      <td>today is which day of the week</td>\n      <td>date</td>\n    </tr>\n  </tbody>\n</table>\n<p>3000 rows Ã— 2 columns</p>\n</div>",
      "text/plain": "                                                 Phrase  \\\n0             tell me what the gas mileage is on my car   \n1     i'd like to know the last time my car got look...   \n2     can i put in a pto request for september 1st t...   \n3                   did carrots get on my shopping list   \n4     will i get charged for using my credit card in...   \n...                                                 ...   \n2995                                        date please   \n2996            when will i received a replacement card   \n2997                      tell ann and scott where i am   \n2998            can you please disconnect from my phone   \n2999                     today is which day of the week   \n\n                         Intent  \n0                           mpg  \n1              last_maintenance  \n2                   pto_request  \n3                 shopping_list  \n4            international_fees  \n...                         ...  \n2995                       date  \n2996  replacement_card_duration  \n2997             share_location  \n2998                sync_device  \n2999                       date  \n\n[3000 rows x 2 columns]"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'sdf'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'sdf'\n",
    "s[::1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dialogflow_NLU\n",
    "\n",
    "import dialogflow_v2 as dialogflow\n",
    "import os\n",
    "\n",
    "credentials_file = 'newagent-fpxjnq-08c3138e5a20.json'  \n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = credentials_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'newagent-fpxjnq'\n",
    "language_code = ''\n",
    "display_name = list(['delete', 'transfer', 'alarm'])\n",
    "training_phrases_parts = list([['delete the row please.', 'delete the column please.'],\n",
    "                            ['transfer 50 euro please', 'i want to make transfer', 'transfer money'],\n",
    "                            ['set alarm', 'set clock at 6', 'remind me at 9pm']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogflow_NLU.create_intent(project_id, display_name, training_phrases_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogflow_NLU.train_agent(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query text: transfer money\n",
      "Detected intent: transfer\n",
      "Detected intent confidence: 1.0\n",
      "Query text: set alarm\n",
      "Detected intent: alarm\n",
      "Detected intent confidence: 1.0\n"
     ]
    }
   ],
   "source": [
    "text_to_be_analyzed = ['transfer money', 'set alarm']\n",
    "\n",
    "for text in text_to_be_analyzed:\n",
    "    dialogflow_NLU.detect_intent(project_id, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent before delete:  0\n",
      "--------------------\n",
      "Intent after delete:  0\n"
     ]
    }
   ],
   "source": [
    "dialogflow_NLU.delete_all_intents(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_file = '/users/xinsun/Downloads/oos-eval-master/data/data_full.json'\n",
    "df = pd.read_json(data_file, typ='series')\n",
    "\n",
    "df_oos_train = pd.DataFrame(df['oos_train'], columns=['Phrase', 'Intent'])\n",
    "df_oos_test = pd.DataFrame(df['oos_test'], columns=['Phrase', 'Intent'])\n",
    "df_oos_val = pd.DataFrame(df['oos_val'], columns=['Phrase', 'Intent'])\n",
    "df_train = pd.DataFrame(df['train'], columns=['Phrase', 'Intent'])\n",
    "df_test = pd.DataFrame(df['test'], columns=['Phrase', 'Intent'])\n",
    "df_val = pd.DataFrame(df['val'], columns=['Phrase', 'Intent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "intents_set = list(df_train['Intent'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_set = [list(df_train[df_train.Intent==intent].Phrase.values) for intent in intents_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'translate'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['what expression would i use to say i love you if i were an italian',\n",
       " \"can you tell me how to say 'i do not speak much spanish', in spanish\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_set[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'newagent-fpxjnq'\n",
    "language_code = ''\n",
    "display_name = intents_set[:30]\n",
    "training_phrases_parts = phrases_set[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent before delete:  0\n",
      "--------------------\n",
      "Intent after delete:  0\n"
     ]
    }
   ],
   "source": [
    "dialogflow_NLU.delete_all_intents(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogflow_NLU.create_intent(project_id, display_name, training_phrases_parts)\n",
    "\n",
    "dialogflow_NLU.train_agent(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query text: transfer money\n",
      "Detected intent: transfer\n",
      "Detected intent confidence: 0.8908178806304932\n",
      "Query text: how can i say in english\n",
      "Detected intent: translate\n",
      "Detected intent confidence: 0.8272097110748291\n",
      "Query text: set the alarm\n",
      "Detected intent: \n",
      "Detected intent confidence: 0.0\n"
     ]
    }
   ],
   "source": [
    "text_to_be_analyzed = ['transfer money', 'how can i say in english', 'set the alarm']\n",
    "\n",
    "for i in range(len(text_to_be_analyzed)):\n",
    "    dialogflow_NLU.detect_intent(project_id, text_to_be_analyzed[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intent before delete:  50\n",
      "--------------------\n",
      "Intent after delete:  0\n"
     ]
    }
   ],
   "source": [
    "dialogflow_NLU.delete_all_intents(project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the sub-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_file = './data/data_full.json'\n",
    "\n",
    "# get the test dataset\n",
    "df = pd.read_json(data_file, typ='series')\n",
    "df_test = pd.DataFrame(df['test'], columns=['Phrase', 'Intent'])\n",
    "df_oov_test = pd.DataFrame(df['oos_test'], columns=['Phrase', 'Intent'])\n",
    "df_test = pd.concat([df_test, df_oov_test]).reset_index(drop=True)\n",
    "\n",
    "write_test_file = './data/df_test.csv'\n",
    "\n",
    "df_test[['Phrase', 'Intent']].to_csv(write_test_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(write_test_file, index_col=0)\n",
    "len(test.Intent.unique())\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "31\n91\n(44, 10)\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d1 = './dialogflow_result/cl_cluster/dialogflow_eval_result_cl_1.csv'\n",
    "d2 = './dialogflow_result/cl_cluster/dialogflow_eval_result_cl_2.csv'\n",
    "d3 = './dialogflow_result/cl_cluster/dialogflow_eval_result_cl_3.csv'\n",
    "d4 = './dialogflow_result/cl_cluster/dialogflow_eval_result_cl_4.csv'\n",
    "d5 = './dialogflow_result/cl_cluster/dialogflow_eval_result_cl_5.csv'\n",
    "d6 = './dialogflow_result/cl_cluster/dialogflow_eval_result_cl_6.csv'\n",
    "d7 = './dialogflow_result/cl_cluster/dialogflow_eval_result_cl_7.csv'\n",
    "d8 = './dialogflow_result/cl_cluster/dialogflow_eval_result_cl_8.csv'\n",
    "\n",
    "d9 = './dialogflow_result/cl_cluster/dialogflow_eval_result_cl_9.csv'\n",
    "d10 = './dialogflow_result/cl_cluster/dialogflow_eval_result_cl_10.csv'\n",
    "d11 = './dialogflow_result/cl_cluster/dialogflow_eval_result_cl_11.csv'\n",
    "d12 = './dialogflow_result/cl_cluster/dialogflow_eval_result_cl_12.csv'\n",
    "d13 = './dialogflow_result/cl_cluster/dialogflow_eval_result_cl_13.csv'\n",
    "\n",
    "model_set_cl = eval(open('./dialogflow_result/cl_cluster/model_set_cl.txt', 'r').readlines()[0])\n",
    "\n",
    "model_set_cl_2 = eval(open('./dialogflow_result/cl_cluster/model_set_cl_2.txt', 'r').readlines()[0])\n",
    "print(len(model_set_cl))\n",
    "print(len(model_set_cl_2))\n",
    "\n",
    "# get the test dataset\n",
    "df1 = pd.read_csv(d1, index_col=0)\n",
    "df2 = pd.read_csv(d2, index_col=0)\n",
    "df3 = pd.read_csv(d3, index_col=0)\n",
    "df4 = pd.read_csv(d4, index_col=0)\n",
    "df5 = pd.read_csv(d5, index_col=0)\n",
    "df6 = pd.read_csv(d6, index_col=0)\n",
    "df7 = pd.read_csv(d7, index_col=0)\n",
    "df8 = pd.read_csv(d8, index_col=0)\n",
    "\n",
    "df9 = pd.read_csv(d9, index_col=0)\n",
    "df10 = pd.read_csv(d10, index_col=0)\n",
    "df11 = pd.read_csv(d11, index_col=0)\n",
    "df12 = pd.read_csv(d12, index_col=0)\n",
    "df13 = pd.read_csv(d13, index_col=0)\n",
    "\n",
    "\n",
    "df_cl = pd.concat([df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13]).reset_index(drop=True)\n",
    "print(df_cl.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model_name</th>\n      <th>dim1_rm</th>\n      <th>dim2_sent_len</th>\n      <th>dim3_sent_num</th>\n      <th>dim4_pattern</th>\n      <th>dim5_SDPs</th>\n      <th>dim6_keywords</th>\n      <th>overall_accuracy</th>\n      <th>overall_precision</th>\n      <th>overall_f1_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>False-False-False-question-True-False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>question</td>\n      <td>True</td>\n      <td>False</td>\n      <td>0.488743</td>\n      <td>0.619705</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>False-False-False-question-False-True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>question</td>\n      <td>False</td>\n      <td>True</td>\n      <td>0.568227</td>\n      <td>0.665787</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                              model_name  dim1_rm dim2_sent_len dim3_sent_num  \\\n0  False-False-False-question-True-False    False         False         False   \n1  False-False-False-question-False-True    False         False         False   \n\n  dim4_pattern  dim5_SDPs  dim6_keywords  overall_accuracy  overall_precision  \\\n0     question       True          False          0.488743           0.619705   \n1     question      False           True          0.568227           0.665787   \n\n   overall_f1_score  \n0               NaN  \n1               NaN  "
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cl.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "60\n(50, 10)\n"
    }
   ],
   "source": [
    "d0 = './dialogflow_result/gcp/dialogflow_eval_result_0.csv'\n",
    "d1 = './dialogflow_result/gcp/dialogflow_eval_result_1.csv'\n",
    "d2 = './dialogflow_result/gcp/dialogflow_eval_result_2.csv'\n",
    "d3 = './dialogflow_result/gcp/dialogflow_eval_result_3.csv'\n",
    "d4 = './dialogflow_result/gcp/dialogflow_eval_result_4.csv'\n",
    "d5 = './dialogflow_result/gcp/dialogflow_eval_result_5.csv'\n",
    "d6 = './dialogflow_result/gcp/dialogflow_eval_result_6.csv'\n",
    "d7 = './dialogflow_result/gcp/dialogflow_eval_result_7.csv'\n",
    "d8 = './dialogflow_result/gcp/dialogflow_eval_result_8.csv'\n",
    "d9 = './dialogflow_result/gcp/dialogflow_eval_result_9.csv'\n",
    "d10 = './dialogflow_result/gcp/dialogflow_eval_result_10.csv'\n",
    "d11 = './dialogflow_result/gcp/dialogflow_eval_result_11.csv'\n",
    "d12 = './dialogflow_result/gcp/dialogflow_eval_result_12.csv'\n",
    "d13 = './dialogflow_result/gcp/dialogflow_eval_result_13.csv'\n",
    "\n",
    "model_set_gcp = eval(open('./dialogflow_result/gcp/model_set.txt', 'r').readlines()[0])\n",
    "print(len(model_set_gcp))\n",
    "\n",
    "\n",
    "# get the test dataset\n",
    "df0 = pd.read_csv(d0, index_col=0)\n",
    "df1 = pd.read_csv(d1, index_col=0)\n",
    "df2 = pd.read_csv(d2, index_col=0)\n",
    "df3 = pd.read_csv(d3, index_col=0)\n",
    "df4 = pd.read_csv(d4, index_col=0)\n",
    "df5 = pd.read_csv(d5, index_col=0)\n",
    "df6 = pd.read_csv(d6, index_col=0)\n",
    "df7 = pd.read_csv(d7, index_col=0)\n",
    "df8 = pd.read_csv(d8, index_col=0)\n",
    "df9 = pd.read_csv(d9, index_col=0)\n",
    "df10 = pd.read_csv(d10, index_col=0)\n",
    "df11 = pd.read_csv(d11, index_col=0)\n",
    "df12 = pd.read_csv(d12, index_col=0)\n",
    "df13 = pd.read_csv(d13, index_col=0)\n",
    "\n",
    "\n",
    "df_gcp = pd.concat([df0, df1, df2, df3, df4, df5, df6, df7, df8, df9, df10, df11, df12, df13]).reset_index(drop=True)\n",
    "print(df_gcp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "90\n"
    },
    {
     "data": {
      "text/plain": "[[True, False, False, False, False, True],\n [True, False, False, False, False, False],\n [True, False, False, 'statement', True, False],\n [True, False, False, 'statement', False, True],\n [True, False, False, 'statement', False, False],\n [True, False, False, 'question', True, False],\n [True, False, False, 'question', False, True],\n [True, False, False, 'question', False, False],\n [True, False, 15, False, True, False],\n [True, False, False, False, True, False],\n [True, False, 15, False, False, True],\n [True, False, 15, False, False, False],\n [True, False, 15, 'statement', True, False],\n [True, False, 15, 'statement', False, True],\n [True, False, 15, 'statement', False, False],\n [True, False, 15, 'question', True, False],\n [True, False, 15, 'question', False, True],\n [True, False, 15, 'question', False, False],\n [True, False, 50, False, True, False],\n [True, False, 50, False, False, True],\n [True, False, 50, False, False, False],\n [True, False, 50, 'statement', True, False],\n [True, False, 50, 'statement', False, True],\n [True, False, 50, 'statement', False, False],\n [True, False, 50, 'question', True, False],\n [True, False, 50, 'question', False, True],\n [True, False, 50, 'question', False, False],\n [True, 5, False, False, False, False],\n [True, 5, False, 'statement', False, False],\n [True, 5, False, 'question', False, False],\n [True, 5, 15, False, False, False],\n [True, 5, 15, 'statement', False, False],\n [True, 5, 15, 'question', False, False],\n [True, 5, 50, False, False, False],\n [True, 5, 50, 'statement', False, False],\n [True, 5, 50, 'question', False, False],\n [True, 15, False, False, False, False],\n [True, 15, False, 'statement', False, False],\n [True, 15, False, 'question', False, False],\n [True, 15, 15, False, False, False],\n [True, 15, 15, 'statement', False, False],\n [True, 15, 15, 'question', False, False],\n [True, 15, 50, False, False, False],\n [True, 15, 50, 'statement', False, False],\n [True, 15, 50, 'question', False, False],\n [False, False, False, False, True, False],\n [False, False, False, False, False, True],\n [False, False, False, False, False, False],\n [False, False, False, 'statement', True, False],\n [False, False, False, 'statement', False, True],\n [False, False, 50, 'question', False, True],\n [False, False, 50, 'question', False, False],\n [False, 5, False, False, False, False],\n [False, 5, False, 'statement', False, False],\n [False, 5, False, 'question', False, False],\n [False, 5, 15, False, False, False],\n [False, 5, 15, 'statement', False, False],\n [False, 5, 15, 'question', False, False],\n [False, 5, 50, False, False, False],\n [False, 5, 50, 'statement', False, False],\n [False, False, False, 'question', True, False],\n [False, False, False, 'question', False, True],\n [False, False, False, 'question', False, False],\n [False, False, 15, False, False, True],\n [False, False, 15, False, False, False],\n [False, False, 15, 'statement', True, False],\n [False, False, 15, 'statement', False, True],\n [False, False, 15, 'statement', False, False],\n [False, False, 15, 'question', True, False],\n [False, False, 15, 'question', False, True],\n [False, False, 15, 'question', False, False],\n [False, False, 50, False, True, False],\n [False, False, 50, False, False, True],\n [False, False, 50, False, False, False],\n [False, False, 50, 'statement', True, False],\n [False, False, 50, 'statement', False, False],\n [False, False, 50, 'question', True, False],\n [False, 5, 50, 'question', False, False],\n [False, 15, False, False, False, False],\n [False, 15, False, 'statement', False, False],\n [False, 15, False, 'question', False, False],\n [False, 15, 15, False, False, False],\n [False, 15, 15, 'question', False, False],\n [False, 15, 50, False, False, False],\n [False, 15, 50, 'statement', False, False],\n [False, 15, 50, 'question', False, False],\n [False, False, False, 'statement', False, False],\n [False, False, 15, False, True, False],\n [False, False, 50, 'statement', False, True],\n [False, 15, 15, 'statement', False, False]]"
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_set_plan = model_set_gcp\n",
    "for i in model_set_cl_2:\n",
    "    if i not in model_set_plan:\n",
    "        model_set_plan.append(i)\n",
    "\n",
    "print(len(model_set_plan))\n",
    "\n",
    "model_set_plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "\"df_cl['model']=None\\nfor i in range(len(df_cl)):\\n    df_cl.loc[i, 'model'] = df_cl.loc[i,'model_name'].replace('-', ', ')\\nmodel_cl_done = list(df_cl['model'].values)\""
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_gcp['model']=None\n",
    "for i in range(len(df_gcp)):\n",
    "    df_gcp.loc[i, 'model'] = str(df_gcp.loc[i,'dim1_rm'])+', '+str(df_gcp.loc[i,'dim2_sent_len'])+', '+str(df_gcp.loc[i,'dim3_sent_num'])+', '+str(df_gcp.loc[i,'dim4_pattern'])+', '+str(df_gcp.loc[i,'dim5_SDPs'])+', '+str(df_gcp.loc[i,'dim6_keywords'])\n",
    "\n",
    "model_gcp_done=[]\n",
    "for i in df_gcp['model'].values:\n",
    "    model_gcp_done.append(i)'''\n",
    "\n",
    "\n",
    "'''df_cl['model']=None\n",
    "for i in range(len(df_cl)):\n",
    "    df_cl.loc[i, 'model'] = df_cl.loc[i,'model_name'].replace('-', ', ')\n",
    "model_cl_done = list(df_cl['model'].values)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "\"f_cl = open('./dialogflow_result/cl_cluster/model_cl_done.txt', 'w+')\\nf_cl.write(str(model_cl_done))\\nf_cl.close()\""
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''f_gcp = open('./dialogflow_result/gcp/model_gcp_done.txt', 'w+')\n",
    "f_gcp.write(str(model_gcp_done))\n",
    "f_gcp.close()'''\n",
    "\n",
    "'''f_cl = open('./dialogflow_result/cl_cluster/model_cl_done.txt', 'w+')\n",
    "f_cl.write(str(model_cl_done))\n",
    "f_cl.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gcp_done = eval(open('./dialogflow_result/gcp/model_gcp_done.txt', 'r').readlines()[0])\n",
    "\n",
    "model_cl_done = eval(open('./dialogflow_result/cl_cluster/model_cl_done.txt', 'r').readlines()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "model_set_done = model_gcp_done\n",
    "for i in model_cl_done:\n",
    "    if i not in model_set_done:\n",
    "        model_set_done.append(i)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''len(model_set_done)\n",
    "\n",
    "f_done = open('./dialogflow_result/model_set_done.txt', 'w+')\n",
    "f_done.write(str(model_set_done))\n",
    "f_done.close()\n",
    "\n",
    "f_plan = open('./dialogflow_result/model_set_plan.txt', 'w+')\n",
    "f_plan.write(str(model_set_plan))\n",
    "f_plan.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.concat([df_gcp, df_cl])\n",
    "\n",
    "df_result_nodup = df_result.drop_duplicates('model_name', keep='first', inplace=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_nodup.to_csv('/Users/xinsun/Dev_env/Bot.Dataset.final/Dialogflow/dialogflow_result/dialogflow_result_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bit8d437ac45ab1400083d7026870debc43"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}